{"cells":[{"cell_type":"markdown","source":["##### Assignment 3:  TFIDF Using Data Frames\n\nNow you will do TF-IDF calculation one more time:  first we did it using MapReduce, in class we did it using Spark RDDs, and now you will do it using Spark Data Frames.\n\nIn Assignment 1 you wrote an interactive query scorer that read the indexed documents and computed TF-IDF for a query line.\nFor this assignment you will implement the same indexing phase (producing a data frame with the computed TF-IDF values), but you will do query processing in batch:\nyou will take a file with one query per line, and produce a data frame with the queries, best matching document, and score of the best matching document."],"metadata":{}},{"cell_type":"code","source":["sc"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.172.234.72:44831\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.4</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        "]}}],"execution_count":2},{"cell_type":"code","source":["%fs rm -r FileStore/tables/documents"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res3: Boolean = false\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["%fs ls FileStore/tables/documents"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/documents/bible_kjv-ef3b8.txt</td><td>bible_kjv-ef3b8.txt</td><td>4332554</td></tr><tr><td>dbfs:/FileStore/tables/documents/carroll_alice-ac78c.txt</td><td>carroll_alice-ac78c.txt</td><td>144395</td></tr><tr><td>dbfs:/FileStore/tables/documents/melville_moby_dick-7006e.txt</td><td>melville_moby_dick-7006e.txt</td><td>1265914</td></tr><tr><td>dbfs:/FileStore/tables/documents/shakespeare_macbeth-08fa9.txt</td><td>shakespeare_macbeth-08fa9.txt</td><td>100351</td></tr><tr><td>dbfs:/FileStore/tables/documents/whitman_leaves-013de.txt</td><td>whitman_leaves-013de.txt</td><td>711215</td></tr></tbody></table></div>"]}}],"execution_count":4},{"cell_type":"code","source":["from pyspark.sql.types import StringType\nfrom pyspark.sql.types import ArrayType\nfrom pyspark.sql.functions import udf, col, lit\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql.functions import explode\nfrom pyspark.sql.functions import regexp_extract\nimport pyspark.sql.functions as func\nfrom pyspark.sql.functions import length\nfrom pyspark.sql.functions import min, max\nfrom pyspark.sql.types import StringType\nfrom pyspark.sql.functions import desc\nfrom pyspark.sql.types import *"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["def splitRow(row):\n  return row.strip().split()\nsplitRowUDF = udf(lambda r: splitRow(r), ArrayType(StringType()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["def termify(word):\n  return ''.join([c for c in word.lower() if 97 <= ord(c) <= 122])\ntermifyUDF = udf(lambda w: termify(w), StringType())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["# This is you indexing function; it must have this signature.\n# The first argument is the name of the directory where the documents reside\n# The output is the name of a file that will be the stored TF-IDF data frame -- you \n# will store the file in Parquet format.\n\n# You must use DataFrames only, in the following sense:\n#   You can use wholeTextFiles to read the documents, which gives you a list of pairs:  the first element of each pair is\n#     the pathname of the file, the second element of the pair is the whole file text.\n#   You must immediately convert this list to a data frame with columns 'pathname' and 'text' and use only \n#     data frame operations for the rest of the function.\n#   Within the function you should first build a data frame with the columns 'Term', 'DocID', and 'TFIDF';  the first two\n#     are strings, the third is a float.  \n#   Scale the TF-IDF values as follows:   divide the value by the maximum value over all (term, docID) rows, and multiply by 100.\n#   The last step in the function is to write the data frame in parquet format to the specified output file name\n\ndef index(indir, outfile): \n  dbutils.fs.rm(outfile,True)\n  textFiles = sc.wholeTextFiles(indir)\n  sq = SQLContext(sc)\n  df = sq.createDataFrame(textFiles).withColumnRenamed(\"_1\", \"pathname\").withColumnRenamed(\"_2\", \"text\")\n  regex_str = \"[\\/]([^\\/]+)$\"\n  df = df.withColumn(\"docid\", regexp_extract(\"pathname\",regex_str,1)).drop(\"pathname\") #get file name only\n  df = df.withColumn(\"words\", splitRowUDF(col(\"text\"))).drop(\"text\")\n  df = df.select(df.docid, explode(df.words).alias(\"word\"))\n  df = df.withColumn(\"term\", termifyUDF(col(\"word\"))).drop('word')\n  df = df.filter(length(df.term) > 0) #Make sure word is atleast 1\n  \n  #create separate dataframe to help compute tfidf\n  termDocCount = df.groupBy(\"term\", \"docid\").count().withColumnRenamed(\"count\", \"termInDocCount\")\n  docLength = df.groupBy(\"docid\").count().withColumnRenamed(\"count\", \"totalTermsInDoc\")\n  termDocFreq = df.distinct().groupBy('term').count().withColumnRenamed(\"count\", \"termInDocFreq\")\n  \n  #Getting tfidf\n  #(docid, term, termInDocCount, totalTermsInDoc)\n  firstJoin = termDocCount.join(docLength, on =[\"docid\"])\n  #(term, docid, termInDocCount, totalTermsInDoc)\n  tfidf = firstJoin.join(termDocFreq, on =[\"term\"])\n  tfidf = tfidf.withColumn(\"temp\", ((tfidf.termInDocCount/tfidf.totalTermsInDoc)/tfidf.termInDocFreq))\n  tfidf = tfidf.withColumn(\"tfidf\", (tfidf.temp/(tfidf.select(max(\"temp\")).collect()[0][0])*100))                         \n  tfidf.select(\"term\", \"docid\", \"tfidf\").write.save(outfile, format='parquet')\n  \n  print(tfidf.take(30))\n  \n  \nindexFileName = '/FileStore/tfidf.parquet'\nindex('/FileStore/tables/documents', indexFileName)\n  \n   # Your code here\n   # Yes, this is a trap -- you had better delete these comment lines :-)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[Row(term=&#39;acheron&#39;, docid=&#39;shakespeare_macbeth-08fa9.txt&#39;, termInDocCount=1, totalTermsInDoc=17649, termInDocFreq=1, temp=5.666043401892458e-05, tfidf=0.3428637042101391), Row(term=&#39;adamic&#39;, docid=&#39;whitman_leaves-013de.txt&#39;, termInDocCount=2, totalTermsInDoc=121375, termInDocFreq=1, temp=1.64778578784758e-05, tfidf=0.09971083856815237), Row(term=&#39;ammonites&#39;, docid=&#39;bible_kjv-ef3b8.txt&#39;, termInDocCount=23, totalTermsInDoc=790029, termInDocFreq=1, temp=2.9112855350879523e-05, tfidf=0.17616775442282392), Row(term=&#39;apprehensions&#39;, docid=&#39;melville_moby_dick-7006e.txt&#39;, termInDocCount=2, totalTermsInDoc=211802, termInDocFreq=1, temp=9.442781465708538e-06, tfidf=0.057140173516819916), Row(term=&#39;arguments&#39;, docid=&#39;carroll_alice-ac78c.txt&#39;, termInDocCount=1, totalTermsInDoc=26382, termInDocFreq=4, temp=9.476157986505951e-06, tfidf=0.057342141570054836), Row(term=&#39;arguments&#39;, docid=&#39;melville_moby_dick-7006e.txt&#39;, termInDocCount=2, totalTermsInDoc=211802, termInDocFreq=4, temp=2.3606953664271346e-06, tfidf=0.014285043379204979), Row(term=&#39;arguments&#39;, docid=&#39;bible_kjv-ef3b8.txt&#39;, termInDocCount=1, totalTermsInDoc=790029, termInDocFreq=4, temp=3.164440799008644e-07, tfidf=0.0019148668959002599), Row(term=&#39;arguments&#39;, docid=&#39;whitman_leaves-013de.txt&#39;, termInDocCount=3, totalTermsInDoc=121375, termInDocFreq=4, temp=6.179196704428424e-06, tfidf=0.03739156446305713), Row(term=&#39;art&#39;, docid=&#39;shakespeare_macbeth-08fa9.txt&#39;, termInDocCount=18, totalTermsInDoc=17649, termInDocFreq=4, temp=0.00025497195308516065, tfidf=1.5428866689456264), Row(term=&#39;art&#39;, docid=&#39;melville_moby_dick-7006e.txt&#39;, termInDocCount=41, totalTermsInDoc=211802, termInDocFreq=4, temp=4.8394255011756264e-05, tfidf=0.29284338927370207), Row(term=&#39;art&#39;, docid=&#39;bible_kjv-ef3b8.txt&#39;, termInDocCount=494, totalTermsInDoc=790029, termInDocFreq=4, temp=0.000156323375471027, tfidf=0.9459442465747284), Row(term=&#39;art&#39;, docid=&#39;whitman_leaves-013de.txt&#39;, termInDocCount=22, totalTermsInDoc=121375, termInDocFreq=4, temp=4.5314109165808446e-05, tfidf=0.27420480606241904), Row(term=&#39;ascriptions&#39;, docid=&#39;melville_moby_dick-7006e.txt&#39;, termInDocCount=1, totalTermsInDoc=211802, termInDocFreq=1, temp=4.721390732854269e-06, tfidf=0.028570086758409958), Row(term=&#39;ashkenaz&#39;, docid=&#39;bible_kjv-ef3b8.txt&#39;, termInDocCount=1, totalTermsInDoc=790029, termInDocFreq=1, temp=1.2657763196034576e-06, tfidf=0.0076594675836010396), Row(term=&#39;augures&#39;, docid=&#39;shakespeare_macbeth-08fa9.txt&#39;, termInDocCount=1, totalTermsInDoc=17649, termInDocFreq=1, temp=5.666043401892458e-05, tfidf=0.3428637042101391), Row(term=&#39;avows&#39;, docid=&#39;whitman_leaves-013de.txt&#39;, termInDocCount=2, totalTermsInDoc=121375, termInDocFreq=1, temp=1.64778578784758e-05, tfidf=0.09971083856815237), Row(term=&#39;barrier&#39;, docid=&#39;whitman_leaves-013de.txt&#39;, termInDocCount=1, totalTermsInDoc=121375, termInDocFreq=1, temp=8.2389289392379e-06, tfidf=0.049855419284076184), Row(term=&#39;battlefront&#39;, docid=&#39;whitman_leaves-013de.txt&#39;, termInDocCount=1, totalTermsInDoc=121375, termInDocFreq=1, temp=8.2389289392379e-06, tfidf=0.049855419284076184), Row(term=&#39;besmoked&#39;, docid=&#39;melville_moby_dick-7006e.txt&#39;, termInDocCount=1, totalTermsInDoc=211802, termInDocFreq=1, temp=4.721390732854269e-06, tfidf=0.028570086758409958), Row(term=&#39;besom&#39;, docid=&#39;bible_kjv-ef3b8.txt&#39;, termInDocCount=1, totalTermsInDoc=790029, termInDocFreq=1, temp=1.2657763196034576e-06, tfidf=0.0076594675836010396), Row(term=&#39;bidders&#39;, docid=&#39;whitman_leaves-013de.txt&#39;, termInDocCount=1, totalTermsInDoc=121375, termInDocFreq=1, temp=8.2389289392379e-06, tfidf=0.049855419284076184), Row(term=&#39;biting&#39;, docid=&#39;melville_moby_dick-7006e.txt&#39;, termInDocCount=4, totalTermsInDoc=211802, termInDocFreq=1, temp=1.8885562931417077e-05, tfidf=0.11428034703363983), Row(term=&#39;blackish&#39;, docid=&#39;melville_moby_dick-7006e.txt&#39;, termInDocCount=1, totalTermsInDoc=211802, termInDocFreq=2, temp=2.3606953664271346e-06, tfidf=0.014285043379204979), Row(term=&#39;blackish&#39;, docid=&#39;bible_kjv-ef3b8.txt&#39;, termInDocCount=1, totalTermsInDoc=790029, termInDocFreq=2, temp=6.328881598017288e-07, tfidf=0.0038297337918005198), Row(term=&#39;blossom&#39;, docid=&#39;melville_moby_dick-7006e.txt&#39;, termInDocCount=1, totalTermsInDoc=211802, termInDocFreq=3, temp=1.573796910951423e-06, tfidf=0.009523362252803319), Row(term=&#39;blossom&#39;, docid=&#39;bible_kjv-ef3b8.txt&#39;, termInDocCount=6, totalTermsInDoc=790029, termInDocFreq=3, temp=2.531552639206915e-06, tfidf=0.015318935167202079), Row(term=&#39;blossom&#39;, docid=&#39;whitman_leaves-013de.txt&#39;, termInDocCount=4, totalTermsInDoc=121375, termInDocFreq=3, temp=1.0985238585650533e-05, tfidf=0.06647389237876825), Row(term=&#39;boatthe&#39;, docid=&#39;melville_moby_dick-7006e.txt&#39;, termInDocCount=1, totalTermsInDoc=211802, termInDocFreq=1, temp=4.721390732854269e-06, tfidf=0.028570086758409958), Row(term=&#39;bookshelf&#39;, docid=&#39;whitman_leaves-013de.txt&#39;, termInDocCount=1, totalTermsInDoc=121375, termInDocFreq=1, temp=8.2389289392379e-06, tfidf=0.049855419284076184), Row(term=&#39;bottomed&#39;, docid=&#39;melville_moby_dick-7006e.txt&#39;, termInDocCount=1, totalTermsInDoc=211802, termInDocFreq=1, temp=4.721390732854269e-06, tfidf=0.028570086758409958)]\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["from pyspark.sql.functions import min, max\n\nperson = spark.createDataFrame([\n(0, \"Bill Chambers\", 0, 100),\n(1, \"Matei Zaharia\", 1, 500), (2, \"Michael Armbrust\", 1, 250)])\\\n.toDF(\"id\", \"name\", \"graduate_program\", \"spark_status\")\n\n#person.show()\nperson.select(max(\"spark_status\")).collect()[0][0]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[44]: 500</div>"]}}],"execution_count":9},{"cell_type":"code","source":["\n# This is a helper function that you must implement.  It does the TF-IDF calculation \n# for a single query line.   Its first input is the query line (a string). The second input\n# is the data frame containing the indexed TF-IDF information -- i.e. it was created in \n# the index phase, and will be read from parquet as the first line of scoreQueryFile below.\n\n# This helper function must return a data frame with columns DocID and Score and will \n# have no rows with score 0 and will be in descending order of score.  I.e.  first \n# row has the docID and score with highest TF-IDF value.  Remember, the TFIDF of a set of \n# terms for a document is the sum of the TFIDF values for each term in the set.\n#\n# This function must use only data frames.  It must first convert the queryLine into a data frame with \n# a single column Word and one row for each word in the query.  It then does the TFIDF calculation using \n# only data frame operations on the query dataframe and the TFIDF dataframe.\n\ndef scoreQueryLine(queryLine, tfidfTable):\n  myList = queryLine.split(\" \")\n  sq = SQLContext(sc)\n  df = sq.createDataFrame(myList, StringType())\n  df = df.withColumn(\"term\", termifyUDF(col(\"value\"))).drop('value')\n  df = df.filter(length(df.term) > 0) #Make sure word is atleast 1\n  #score = spark.read.parquet(tfidfTable)\n  final = df.join(tfidfTable, on = [\"term\"])\n  docid_score = final.groupBy(\"docid\").sum().withColumnRenamed(\"sum(tfidf)\", \"score\").sort(desc(\"score\"))\n  #docid_score.show()\n  return docid_score\n\n#scoreQueryLine(\"leaves OF grass\", 'FileStore/tfidf.parquet')\n   # Your code here\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["\n# This is your query processing function.   \n# It takes as input the name of a file containing the queries, one line per query.  The second argument\n#  is the name of the Parquet file containing the indexed TF-IDF values.  \n\n# This function returns a DataFrame with three columns:   'Query', 'DocID', and 'Score' \n#   There will be one row for each query in the input file, *unless* there are no documents with non-zero TFIDF for the query.\n#   The docID and score are for the highest-scoring document.  You can break ties automatically.\n\n# This function does not need to use Data Frame operations only, though it does need to return a data frame.\n# In can implement a loop over lines in the query file and call scoreQueryLine sequentially on each line.\n\ndef scoreQueryFile(filename, tfidfFileName='FileStore/tfidf.parquet'):\n  textFile = sc.textFile(filename)\n  tfidf = spark.read.parquet(tfidfFileName)\n  #tfidf.show()\n  sq = SQLContext(sc)\n  field = [StructField(\"query\", StringType(), True),StructField(\"docid\", StringType(), True),StructField(\"score\", FloatType(), True)]\n  schema = StructType(field)\n  result = sq.createDataFrame(sc.emptyRDD(), schema)\n  #result.show()\n  for line in textFile.collect():\n    df = scoreQueryLine(line, tfidf)\n    df = df.withColumn(\"query\", lit(line))\n    df = df.limit(1)\n    #df.show()\n    result = result.union(df)\n  result.show()\n  return result\n    \n  \n\n#scoreQueryFile('/FileStore/tables/queries.txt')\n"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["Do not include the cells below in your handed-in notebook."],"metadata":{}},{"cell_type":"markdown","source":["Here are the files in my documents directory:\n\n<pre>\nbible_kjv-ef3b8.txt\ncarroll_alice-ac78c.txt\nmelville_moby_dick-7006e.txt\nshakespeare_macbeth-08fa9.txt\nwhitman_leaves-013de.txt\n</pre>\n\nNotice they have the strange 5 char ID that gets appended to the file name when it is uploaded to the Databricks filesystem."],"metadata":{}},{"cell_type":"markdown","source":["Here is the content of my queries.txt file\n<pre>\nDead baby whales!\nleaves OF grass\nleaves grass\nkill,  king.\nrabbit HOLE\nmAD hatter\ngod loves\n</pre>"],"metadata":{}},{"cell_type":"markdown","source":["This is how I will run your code, and here is some sample output"],"metadata":{}},{"cell_type":"code","source":["indexFileName = '/FileStore/tfidf.parquet'\nindex('/FileStore/tables/documents', indexFileName)\nscoreQueryFile('/FileStore/tables/queries.txt', indexFileName).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[Row(term=&#39;acheron&#39;, docid=&#39;shakespeare_macbeth-08fa9.txt&#39;, termInDocCount=1, totalTermsInDoc=17649, termInDocFreq=1, temp=5.666043401892458e-05, tfidf=0.3428637042101391), Row(term=&#39;adamic&#39;, docid=&#39;whitman_leaves-013de.txt&#39;, termInDocCount=2, totalTermsInDoc=121375, termInDocFreq=1, temp=1.64778578784758e-05, tfidf=0.09971083856815237), Row(term=&#39;ammonites&#39;, docid=&#39;bible_kjv-ef3b8.txt&#39;, termInDocCount=23, totalTermsInDoc=790029, termInDocFreq=1, temp=2.9112855350879523e-05, tfidf=0.17616775442282392), Row(term=&#39;apprehensions&#39;, docid=&#39;melville_moby_dick-7006e.txt&#39;, termInDocCount=2, totalTermsInDoc=211802, termInDocFreq=1, temp=9.442781465708538e-06, tfidf=0.057140173516819916), Row(term=&#39;arguments&#39;, docid=&#39;carroll_alice-ac78c.txt&#39;, termInDocCount=1, totalTermsInDoc=26382, termInDocFreq=4, temp=9.476157986505951e-06, tfidf=0.057342141570054836), Row(term=&#39;arguments&#39;, docid=&#39;melville_moby_dick-7006e.txt&#39;, termInDocCount=2, totalTermsInDoc=211802, termInDocFreq=4, temp=2.3606953664271346e-06, tfidf=0.014285043379204979), Row(term=&#39;arguments&#39;, docid=&#39;bible_kjv-ef3b8.txt&#39;, termInDocCount=1, totalTermsInDoc=790029, termInDocFreq=4, temp=3.164440799008644e-07, tfidf=0.0019148668959002599), Row(term=&#39;arguments&#39;, docid=&#39;whitman_leaves-013de.txt&#39;, termInDocCount=3, totalTermsInDoc=121375, termInDocFreq=4, temp=6.179196704428424e-06, tfidf=0.03739156446305713), Row(term=&#39;art&#39;, docid=&#39;shakespeare_macbeth-08fa9.txt&#39;, termInDocCount=18, totalTermsInDoc=17649, termInDocFreq=4, temp=0.00025497195308516065, tfidf=1.5428866689456264), Row(term=&#39;art&#39;, docid=&#39;melville_moby_dick-7006e.txt&#39;, termInDocCount=41, totalTermsInDoc=211802, termInDocFreq=4, temp=4.8394255011756264e-05, tfidf=0.29284338927370207), Row(term=&#39;art&#39;, docid=&#39;bible_kjv-ef3b8.txt&#39;, termInDocCount=494, totalTermsInDoc=790029, termInDocFreq=4, temp=0.000156323375471027, tfidf=0.9459442465747284), Row(term=&#39;art&#39;, docid=&#39;whitman_leaves-013de.txt&#39;, termInDocCount=22, totalTermsInDoc=121375, termInDocFreq=4, temp=4.5314109165808446e-05, tfidf=0.27420480606241904), Row(term=&#39;ascriptions&#39;, docid=&#39;melville_moby_dick-7006e.txt&#39;, termInDocCount=1, totalTermsInDoc=211802, termInDocFreq=1, temp=4.721390732854269e-06, tfidf=0.028570086758409958), Row(term=&#39;ashkenaz&#39;, docid=&#39;bible_kjv-ef3b8.txt&#39;, termInDocCount=1, totalTermsInDoc=790029, termInDocFreq=1, temp=1.2657763196034576e-06, tfidf=0.0076594675836010396), Row(term=&#39;augures&#39;, docid=&#39;shakespeare_macbeth-08fa9.txt&#39;, termInDocCount=1, totalTermsInDoc=17649, termInDocFreq=1, temp=5.666043401892458e-05, tfidf=0.3428637042101391), Row(term=&#39;avows&#39;, docid=&#39;whitman_leaves-013de.txt&#39;, termInDocCount=2, totalTermsInDoc=121375, termInDocFreq=1, temp=1.64778578784758e-05, tfidf=0.09971083856815237), Row(term=&#39;barrier&#39;, docid=&#39;whitman_leaves-013de.txt&#39;, termInDocCount=1, totalTermsInDoc=121375, termInDocFreq=1, temp=8.2389289392379e-06, tfidf=0.049855419284076184), Row(term=&#39;battlefront&#39;, docid=&#39;whitman_leaves-013de.txt&#39;, termInDocCount=1, totalTermsInDoc=121375, termInDocFreq=1, temp=8.2389289392379e-06, tfidf=0.049855419284076184), Row(term=&#39;besmoked&#39;, docid=&#39;melville_moby_dick-7006e.txt&#39;, termInDocCount=1, totalTermsInDoc=211802, termInDocFreq=1, temp=4.721390732854269e-06, tfidf=0.028570086758409958), Row(term=&#39;besom&#39;, docid=&#39;bible_kjv-ef3b8.txt&#39;, termInDocCount=1, totalTermsInDoc=790029, termInDocFreq=1, temp=1.2657763196034576e-06, tfidf=0.0076594675836010396), Row(term=&#39;bidders&#39;, docid=&#39;whitman_leaves-013de.txt&#39;, termInDocCount=1, totalTermsInDoc=121375, termInDocFreq=1, temp=8.2389289392379e-06, tfidf=0.049855419284076184), Row(term=&#39;biting&#39;, docid=&#39;melville_moby_dick-7006e.txt&#39;, termInDocCount=4, totalTermsInDoc=211802, termInDocFreq=1, temp=1.8885562931417077e-05, tfidf=0.11428034703363983), Row(term=&#39;blackish&#39;, docid=&#39;melville_moby_dick-7006e.txt&#39;, termInDocCount=1, totalTermsInDoc=211802, termInDocFreq=2, temp=2.3606953664271346e-06, tfidf=0.014285043379204979), Row(term=&#39;blackish&#39;, docid=&#39;bible_kjv-ef3b8.txt&#39;, termInDocCount=1, totalTermsInDoc=790029, termInDocFreq=2, temp=6.328881598017288e-07, tfidf=0.0038297337918005198), Row(term=&#39;blossom&#39;, docid=&#39;melville_moby_dick-7006e.txt&#39;, termInDocCount=1, totalTermsInDoc=211802, termInDocFreq=3, temp=1.573796910951423e-06, tfidf=0.009523362252803319), Row(term=&#39;blossom&#39;, docid=&#39;bible_kjv-ef3b8.txt&#39;, termInDocCount=6, totalTermsInDoc=790029, termInDocFreq=3, temp=2.531552639206915e-06, tfidf=0.015318935167202079), Row(term=&#39;blossom&#39;, docid=&#39;whitman_leaves-013de.txt&#39;, termInDocCount=4, totalTermsInDoc=121375, termInDocFreq=3, temp=1.0985238585650533e-05, tfidf=0.06647389237876825), Row(term=&#39;boatthe&#39;, docid=&#39;melville_moby_dick-7006e.txt&#39;, termInDocCount=1, totalTermsInDoc=211802, termInDocFreq=1, temp=4.721390732854269e-06, tfidf=0.028570086758409958), Row(term=&#39;bookshelf&#39;, docid=&#39;whitman_leaves-013de.txt&#39;, termInDocCount=1, totalTermsInDoc=121375, termInDocFreq=1, temp=8.2389289392379e-06, tfidf=0.049855419284076184), Row(term=&#39;bottomed&#39;, docid=&#39;melville_moby_dick-7006e.txt&#39;, termInDocCount=1, totalTermsInDoc=211802, termInDocFreq=1, temp=4.721390732854269e-06, tfidf=0.028570086758409958)]\n+--------------------+------------------+-----------------+\n               query|             docid|            score|\n+--------------------+------------------+-----------------+\nmelville_moby_dic...| 6.112570061961811|Dead baby whales!|\n bible_kjv-ef3b8.txt| 53.26585244325753|  leaves OF grass|\nwhitman_leaves-01...|1.3585601754910759|     leaves grass|\nshakespeare_macbe...|3.7715007463115304|     kill,  king.|\ncarroll_alice-ac7...|  9.86284835004943|      rabbit HOLE|\ncarroll_alice-ac7...| 6.949867558290645|       mAD hatter|\n bible_kjv-ef3b8.txt| 8.513498219172556|        god loves|\n+--------------------+------------------+-----------------+\n\n+--------------------+------------------+-----------------+\n               query|             docid|            score|\n+--------------------+------------------+-----------------+\nmelville_moby_dic...| 6.112570061961811|Dead baby whales!|\n bible_kjv-ef3b8.txt| 53.26585244325753|  leaves OF grass|\nwhitman_leaves-01...|1.3585601754910759|     leaves grass|\nshakespeare_macbe...|3.7715007463115304|     kill,  king.|\ncarroll_alice-ac7...|  9.86284835004943|      rabbit HOLE|\ncarroll_alice-ac7...| 6.949867558290645|       mAD hatter|\n bible_kjv-ef3b8.txt| 8.513498219172556|        god loves|\n+--------------------+------------------+-----------------+\n\n</div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["<pre>\n+-----------------+-------------------+------------------+\n|            Query|              DocID|             Score|\n+-----------------+-------------------+------------------+\n|Dead baby whales!| melville_moby_dick|6.1125700619618115|\n|  leaves OF grass|          bible_kjv| 53.26585244325753|\n|     leaves grass|     whitman_leaves|1.3585601754910759|\n|     kill,  king.|shakespeare_macbeth|3.7715007463115304|\n|      rabbit HOLE|      carroll_alice|  9.86284835004943|\n|       mAD hatter|      carroll_alice| 6.949867558290645|\n|        god loves|          bible_kjv| 8.513498219172556|\n+-----------------+-------------------+------------------+\n</pre>"],"metadata":{}},{"cell_type":"markdown","source":["Notice the weird behavior of the second and third lines.  \n\nThe problem is that the word 'of' has very high term frequency in the bible, and that dwarfs the effect from the other words.  \n\nDividing by document frequency is supposed to correct for this -- i.e. it gives less weight to words like 'of' that appear in most/all documents.  But with only five documents in the index set, it doesn't \"penalize\" these common words enough.  \n\nThe common solution is to define 'stop words' that are left out of indexing altogether."],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":19}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.0","nbconvert_exporter":"python","file_extension":".py"},"name":"TFIDFForAssignment","notebookId":4279230808524101},"nbformat":4,"nbformat_minor":0}
