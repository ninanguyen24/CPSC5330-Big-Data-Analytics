{"cells":[{"cell_type":"markdown","source":["##### Assignment 2:  TFIDF Using Data Frames\n\nNina Nguyen  \nCPSC 5330   \n3/15/2020"],"metadata":{}},{"cell_type":"code","source":["sc"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.172.253.105:46914\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.5</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[2]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        "]}}],"execution_count":2},{"cell_type":"code","source":["%fs ls FileStore/tables/documents"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/documents/bible_kjv-ef3b8.txt</td><td>bible_kjv-ef3b8.txt</td><td>4332554</td></tr><tr><td>dbfs:/FileStore/tables/documents/carroll_alice-ac78c.txt</td><td>carroll_alice-ac78c.txt</td><td>144395</td></tr><tr><td>dbfs:/FileStore/tables/documents/melville_moby_dick-7006e.txt</td><td>melville_moby_dick-7006e.txt</td><td>1265914</td></tr><tr><td>dbfs:/FileStore/tables/documents/shakespeare_macbeth-08fa9.txt</td><td>shakespeare_macbeth-08fa9.txt</td><td>100351</td></tr><tr><td>dbfs:/FileStore/tables/documents/whitman_leaves-013de.txt</td><td>whitman_leaves-013de.txt</td><td>711215</td></tr></tbody></table></div>"]}}],"execution_count":3},{"cell_type":"code","source":["from pyspark.sql.types import StringType\nfrom pyspark.sql.types import ArrayType\nfrom pyspark.sql.functions import udf, col, lit\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql.functions import explode\nfrom pyspark.sql.functions import regexp_extract\nimport pyspark.sql.functions as func\nfrom pyspark.sql.functions import length\nfrom pyspark.sql.functions import min, max\nfrom pyspark.sql.types import StringType\nfrom pyspark.sql.functions import desc\nfrom pyspark.sql.types import *"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["def splitRow(row):\n  return row.strip().split()\nsplitRowUDF = udf(lambda r: splitRow(r), ArrayType(StringType()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["def termify(word):\n  return ''.join([c for c in word.lower() if 97 <= ord(c) <= 122])\ntermifyUDF = udf(lambda w: termify(w), StringType())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["\n#Read in corpus and calculate tfidf\n#Write term, docid, tfidf to parquet file\ndef index(indir, outfile): \n  dbutils.fs.rm(outfile,True)\n  textFiles = sc.wholeTextFiles(indir)\n  sq = SQLContext(sc)\n  df = sq.createDataFrame(textFiles).withColumnRenamed(\"_1\", \"pathname\").withColumnRenamed(\"_2\", \"text\")\n  regex_str = \"[\\/]([^\\/]+)$\"\n  df = df.withColumn(\"docid\", regexp_extract(\"pathname\",regex_str,1)).drop(\"pathname\") #get file name only\n  df = df.withColumn(\"words\", splitRowUDF(col(\"text\"))).drop(\"text\")\n  df = df.select(df.docid, explode(df.words).alias(\"word\"))\n  df = df.withColumn(\"term\", termifyUDF(col(\"word\"))).drop('word')\n  df = df.filter(length(df.term) > 0) #Make sure word is atleast 1\n  \n  #create separate dataframe to help compute tfidf\n  termDocCount = df.groupBy(\"term\", \"docid\").count().withColumnRenamed(\"count\", \"termInDocCount\")\n  docLength = df.groupBy(\"docid\").count().withColumnRenamed(\"count\", \"totalTermsInDoc\")\n  termDocFreq = df.distinct().groupBy('term').count().withColumnRenamed(\"count\", \"termInDocFreq\")\n  \n  #Getting tfidf\n  firstJoin = termDocCount.join(docLength, on =[\"docid\"])\n  tfidf = firstJoin.join(termDocFreq, on =[\"term\"])\n  tfidf = tfidf.withColumn(\"temp\", ((tfidf.termInDocCount/tfidf.totalTermsInDoc)/tfidf.termInDocFreq))\n  tfidf = tfidf.withColumn(\"tfidf\", (tfidf.temp/(tfidf.select(max(\"temp\")).collect()[0][0])*100))     \n  #Write to output file in parquet format\n  tfidf.select(\"term\", \"docid\", \"tfidf\").write.save(outfile, format='parquet')\n  "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["#Helper function to do TFIDF calculation for a single query line\n#Output is dataframe with docid and score\ndef scoreQueryLine(queryLine, tfidfTable):\n  myList = queryLine.split(\" \")\n  sq = SQLContext(sc)\n  df = sq.createDataFrame(myList, StringType())\n  df = df.withColumn(\"term\", termifyUDF(col(\"value\"))).drop('value')\n  df = df.filter(length(df.term) > 0) #Make sure word is atleast 1\n  final = df.join(tfidfTable, on = [\"term\"])\n  docid_score = final.groupBy(\"docid\").sum().withColumnRenamed(\"sum(tfidf)\", \"score\").sort(desc(\"score\"))\n  return docid_score\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["#Takes in a query file and the output parquet file, calculate the TFIDF score \n#Returns a dataframe with query, docid, score\ndef scoreQueryFile(filename, tfidfFileName='FileStore/tfidf.parquet'):\n  textFile = sc.textFile(filename)\n  tfidf = spark.read.parquet(tfidfFileName)\n  sq = SQLContext(sc)\n  field = [StructField(\"query\", StringType(), True),StructField(\"docid\", StringType(), True),StructField(\"score\", FloatType(), True)]\n  schema = StructType(field)\n  result = sq.createDataFrame(sc.emptyRDD(), schema)\n  for line in textFile.collect():\n    df = scoreQueryLine(line, tfidf)\n    df = df.withColumn(\"query\", lit(line))\n    df = df.limit(1)\n    #df.show()\n    result = result.union(df.select(result.columns))\n  return result\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["indexFileName = '/FileStore/tfidf.parquet'\nindex('/FileStore/tables/documents', indexFileName)\nscoreQueryFile('/FileStore/tables/queries.txt', indexFileName).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------+--------------------+------------------+\n            query|               docid|             score|\n+-----------------+--------------------+------------------+\nDead baby whales!|melville_moby_dic...| 6.112570061961811|\n  leaves OF grass| bible_kjv-ef3b8.txt| 53.26585244325753|\n     leaves grass|whitman_leaves-01...|1.3585601754910759|\n     kill,  king.|shakespeare_macbe...|3.7715007463115304|\n      rabbit HOLE|carroll_alice-ac7...|  9.86284835004943|\n       mAD hatter|carroll_alice-ac7...| 6.949867558290645|\n        god loves| bible_kjv-ef3b8.txt| 8.513498219172556|\n+-----------------+--------------------+------------------+\n\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":11}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.0","nbconvert_exporter":"python","file_extension":".py"},"name":"TFIDFForAssignment","notebookId":4279230808524101},"nbformat":4,"nbformat_minor":0}
